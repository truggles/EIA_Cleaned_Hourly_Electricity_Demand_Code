{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get EIA Demand Data\n",
    "\n",
    "Functions to query EIA's (U.S. Energy Information Administration) OpenData API for hourly electricity demand data.  This notebook generates a single csv file per EIA 1) balancing authority, 2) EIA regions, and 3) contiguous US with all available EIA hourly demand data.\n",
    "\n",
    "\n",
    "Author:\n",
    "T. Ruggles\n",
    "14 June 2019\n",
    "\n",
    "Updated by:\n",
    "A. Wongel\n",
    "January 2025\n",
    "\n",
    "\n",
    "# EIA API Resources\n",
    "\n",
    "EIA provides some commands here: https://www.eia.gov/opendata/documentation.php\n",
    "\n",
    "\n",
    "# EIA Electricity Demand\n",
    "\n",
    "Web interface for EIA electricity demand data: https://www.eia.gov/opendata/browser/electricity/rto/region-data\n",
    "\n",
    "A real-time display of the U.S. interconnect is available here: https://www.eia.gov/realtime_grid/\n",
    "\n",
    "\n",
    "# Details\n",
    "\n",
    "In the cases where the result of the EIA API query skipped\n",
    "an hour, the associated row will have a demand value of `MISSING`.\n",
    "In the cases where the result of the EIA API query returned NONE for\n",
    "an hour, the associated row will have a demand value of `EMPTY`.\n",
    "These values are kept distinct to help inform further study of the EIA data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import datetime\n",
    "from collections import OrderedDict\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting and EIA API key\n",
    "\n",
    "EIA provides open data and an API for accessing them. To use their API you must first get a key here: https://www.eia.gov/opendata/register.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EIA_API_KEY='YOUR_EIA_API_KEY_HERE' # as a string\n",
    "print(EIA_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query EIA to get list of regions for which hourly electricity deman data is available\n",
    "def get_regions_data(ID='region-data', data_type='facets[type][]=D&', start='2020-01-01T00', end='2020-01-02T00'):\n",
    "    # Limiting to a time range to handle EIA API data limit\n",
    "    regions_query = urllib.request.urlopen('https://api.eia.gov/v2/electricity/rto/{}/data/?api_key={}&{}start={}&end={}'.format(ID, EIA_API_KEY, data_type, start, end))\n",
    "    regions_response = regions_query.read().decode('utf-8')\n",
    "    regions_data = json.loads(regions_response)\n",
    "\n",
    "    return regions_data\n",
    "\n",
    "\n",
    "# Query EIA for hour electric demand data for a given region\n",
    "def get_regional_data(region_code, start, end, data_type, ID='region-data'):\n",
    "\n",
    "    # Get region\n",
    "    if not 'sub' in ID:\n",
    "        find_reg_by = 'respondent'\n",
    "    else:\n",
    "        find_reg_by = 'subba'\n",
    "\n",
    "    # Split in chunks of 6 months to avoid EIA API limit\n",
    "    intermed_end_dt = datetime.datetime.strptime(start, '%Y-%m-%d') + datetime.timedelta(180)\n",
    "    intermed_end = intermed_end_dt.strftime('%Y-%m-%d')\n",
    "    region_data = {}\n",
    "    while datetime.datetime.strptime(start, '%Y-%m-%d') < datetime.datetime.strptime(end, '%Y-%m-%d'):\n",
    "        region_query = urllib.request.urlopen(f'https://api.eia.gov/v2/electricity/rto/{ID}/data/?api_key={EIA_API_KEY}&facets[{find_reg_by}][]={region_code}&{data_type}frequency=hourly&data[0]=value&start={start}&end={intermed_end}')\n",
    "        region_response = region_query.read().decode('utf-8')\n",
    "        region_data_chunk = json.loads(region_response)\n",
    "\n",
    "        # Merge with previous data\n",
    "        region_data['response'] = {'data': region_data['response']['data'] + region_data_chunk['response']['data']} if 'response' in region_data else region_data_chunk['response']\n",
    "        start_dt = intermed_end_dt\n",
    "        intermed_end_dt = start_dt + datetime.timedelta(180) if start_dt + datetime.timedelta(180) < datetime.datetime.strptime(end, '%Y-%m-%d') else datetime.datetime.strptime(end, '%Y-%m-%d')\n",
    "        start = start_dt.strftime('%Y-%m-%d')\n",
    "        intermed_end = intermed_end_dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "\n",
    "    # For checking initial raw EIA output\n",
    "    # with open('data/{}_raw.csv'.format(region_code), 'w', newline='') as csvfile:\n",
    "    #    csvfile.write(json.dumps(region_data, sort_keys=True, indent=4))\n",
    "\n",
    "    return region_data\n",
    "\n",
    "\n",
    "# Generate full hourly date and time series from start date ending the hour before end date\n",
    "def generate_full_time_series(start_date, end_date):\n",
    "    full_date_range = []\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        for h in range(24):\n",
    "            full_date_range.append(datetime.datetime.combine(start_date + datetime.timedelta(n), datetime.time(h, 0)))\n",
    "\n",
    "    return full_date_range\n",
    "\n",
    "\n",
    "# Save region hourly electric demand data to a format usable by MEM\n",
    "def save_file(series_id, region_data, full_date_range, tgt_dir):\n",
    "\n",
    "    region_id = series_id.replace('EBA.','').replace('-ALL', '').replace('.D.H','')\n",
    "\n",
    "    with open(tgt_dir+'/{}.csv'.format(region_id), 'w', newline='') as csvfile:\n",
    "\n",
    "        fieldnames = ['date_time', 'demand (MW)']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        full_date_range_dict = OrderedDict()\n",
    "        datetime_format = '%Y-%m-%dT%H'\n",
    "        for hour in full_date_range:\n",
    "            full_date_range_dict[hour.strftime(datetime_format)] = ['MISSING', 'MISSING']\n",
    "\n",
    "        # Actual realized demand\n",
    "        for demand in region_data['response']['data']:\n",
    "            # Skip dates outside the specified range\n",
    "            if demand['period'] not in full_date_range_dict.keys():\n",
    "                continue\n",
    "            try:\n",
    "                if demand['value'] == None:\n",
    "                    full_date_range_dict[demand['period']][0] = 'EMPTY'\n",
    "                else:\n",
    "                    full_date_range_dict[demand['period']][0] = demand['value']\n",
    "            except KeyError:\n",
    "                print(\"Check date and time formatting for category {} for time {}\".format(region_id, demand['period']))\n",
    "\n",
    "        for time, demand_output in full_date_range_dict.items():\n",
    "            \n",
    "            dt = datetime.datetime.strptime(time, datetime_format)\n",
    "            \n",
    "            # From EIA form 930 instructions: \n",
    "            # \"Report all data as hourly integrated values in megawatts by hour ending time.\"\n",
    "            writer.writerow({'date_time': dt,\n",
    "                'demand (MW)': demand_output[0]})\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the quries\n",
    "\n",
    "You can adjust the data range of the output CSV files with `start_date` and `end_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data directory\n",
    "tgt_dir_ba = './data'\n",
    "if not os.path.exists(tgt_dir_ba):\n",
    "    os.mkdir(tgt_dir_ba)\n",
    "\n",
    "regions_data = get_regions_data()\n",
    "# Get unique respondents and respondent names for all regions\n",
    "regions = {(record[\"respondent\"], record[\"respondent-name\"]) for record in regions_data[\"response\"][\"data\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range of interest\n",
    "start_date = datetime.date(2020, 1, 1) # Start date that includes subregion data\n",
    "end_date = datetime.date(2025,1, 1) # Can update this as time progresses\n",
    "full_date_range = generate_full_time_series(start_date, end_date)\n",
    "for reg_code, region_name in regions: \n",
    "    print(\"Getting data for: {} with region code {}\".format(region_name, reg_code))\n",
    "    # data_type 'D' for realized demand\n",
    "    region_data = get_regional_data(reg_code, start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\"), data_type='facets[type][]=D&', ID='region-data')\n",
    "    save_file(reg_code, region_data, full_date_range, tgt_dir_ba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-region demand\n",
    "A few BAs provide hourly demand at a sub-regional level. See a list here: https://www.eia.gov/opendata/browser/electricity/rto/region-sub-ba-data\n",
    "\n",
    "Query these regions for their sub-regional demand profiles. The `Public Service Company of New Mexico (PNM)` BA has two listed sub-regions without any data; these are skipped.\n",
    "\n",
    "Demand for these regions was first reported on:\n",
    " * California Independent System Operator (CISO)\n",
    "  * 2018-07-01 08:00:00\n",
    " * ISO New England (ISNE)\n",
    "  * 2018-07-01 05:00:00\n",
    " * Midcontinent Independent System Operator, Inc. (MISO)\n",
    "  * 2018-07-01 06:00:00\n",
    " * New York Independent System Operator (NYIS)\n",
    "  * 2018-06-19 05:00:00\n",
    " * PJM Interconnection, LLC (PJM)\n",
    "  * 2018-07-01 05:00:00\n",
    "  * substantial data gap before 2018-09-18\n",
    " * Public Service Company of New Mexico (PNM)\n",
    "  * 2018-07-01 08:00:00\n",
    "  * Two subregions have no reported data: FREP and JICA\n",
    " * Southwest Power Pool (SWPP)\n",
    "  * 2018-08-31 06:00:00\n",
    " * Electric Reliability Council of Texas, Inc. (ERCO)\n",
    "  * 2019-05-27 06:00:00\n",
    "\n",
    "By considering data from 1 Jan 2020 through 31 Dec 2024 we have five full years of data to clean and impute for all BAs that report subregions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data directory\n",
    "tgt_dir_sub = './data_subregions'\n",
    "if not os.path.exists(tgt_dir_sub):\n",
    "    os.mkdir(tgt_dir_sub)\n",
    "\n",
    "subregions_data = get_regions_data(ID='region-sub-ba-data', data_type='', start='2020-01-01T00', end='2020-01-02T00')\n",
    "# Get unique respondents and respondent names for all regions\n",
    "subregions = {(record[\"subba\"], record[\"subba-name\"], record[\"parent\"]) for record in subregions_data[\"response\"][\"data\"]}\n",
    "\n",
    "# Date range of interest\n",
    "start_date = datetime.date(2020, 1, 1)\n",
    "end_date = datetime.date(2025, 1, 1) # Can update this as time progresses\n",
    "full_date_range = generate_full_time_series(start_date, end_date)\n",
    "\n",
    "# Subregions\n",
    "for subreg_code, subreg_name, subreg_parent in subregions:\n",
    "\n",
    "    print(\"Getting data for: {} with region code {} (belongs to {})\".format(subreg_name, subreg_code, subreg_parent))\n",
    "    \n",
    "    subreg_data = get_regional_data(subreg_code, start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\"), data_type='', ID='region-sub-ba-data')\n",
    "    \n",
    "    # Catch errors for some subregions without data\n",
    "    if 'data' in subreg_data.keys() and 'error' in subreg_data['data'].keys():\n",
    "        print(subreg_data['data']['error'], \"\\nSkipping this subregion\\n\")\n",
    "        continue\n",
    "    \n",
    "    save_file(subreg_parent+'-'+subreg_code, subreg_data, full_date_range, tgt_dir_sub)\n",
    "\n",
    "# Add BA regions to subregions\n",
    "for reg_code, region_name in regions: \n",
    "    print(\"Copying full BA {} {}\".format(region_name, reg_code))\n",
    "    # Copy the full region data to the subregion directory\n",
    "    shutil.copy(tgt_dir_ba+'/{}.csv'.format(reg_code), tgt_dir_sub+'/{}.csv'.format(reg_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_cleaning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
